{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883b8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
      "Collecting fastapi==0.121.2\n",
      "  Using cached fastapi-0.121.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting pydantic==2.12.3\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting mlflow==2.12.1\n",
      "  Using cached mlflow-2.12.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting torch==2.6.0+cu124\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.21.0+cu124\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting pillow==11.3.0\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting requests==2.32.5\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting uvicorn==0.38.0\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting python-dotenv==1.0.1\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting google-auth==2.29.0\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Requirement already satisfied: ipykernel in /root/.venv/lib/python3.12/site-packages (7.1.0)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi==0.121.2)\n",
      "  Using cached starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi==0.121.2)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi==0.121.2)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic==2.12.3)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic==2.12.3)\n",
      "  Using cached pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic==2.12.3)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting Flask<4 (from mlflow==2.12.1)\n",
      "  Using cached flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow==2.12.1)\n",
      "  Using cached alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow==2.12.1)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cloudpickle<4 (from mlflow==2.12.1)\n",
      "  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow==2.12.1)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting entrypoints<1 (from mlflow==2.12.1)\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow==2.12.1)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting graphene<4 (from mlflow==2.12.1)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow==2.12.1)\n",
      "  Using cached importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow==2.12.1)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting packaging<25 (from mlflow==2.12.1)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas<3 (from mlflow==2.12.1)\n",
      "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting protobuf<6,>=3.12.0 (from mlflow==2.12.1)\n",
      "  Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow<16,>=4.0.0 (from mlflow==2.12.1)\n",
      "  Using cached pyarrow-15.0.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pytz<2025 (from mlflow==2.12.1)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pyyaml<7,>=5.1 (from mlflow==2.12.1)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting querystring-parser<2 (from mlflow==2.12.1)\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting scipy<2 (from mlflow==2.12.1)\n",
      "  Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow==2.12.1)\n",
      "  Using cached sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow==2.12.1)\n",
      "  Using cached sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting Jinja2<4,>=2.11 (from mlflow==2.12.1)\n",
      "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gunicorn<22 (from mlflow==2.12.1)\n",
      "  Using cached gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests==2.32.5)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests==2.32.5)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests==2.32.5)\n",
      "  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.32.5)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting filelock (from torch==2.6.0+cu124)\n",
      "  Using cached filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting networkx (from torch==2.6.0+cu124)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fsspec (from torch==2.6.0+cu124)\n",
      "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Collecting triton==3.2.0 (from torch==2.6.0+cu124)\n",
      "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting setuptools (from torch==2.6.0+cu124)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0+cu124)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting h11>=0.8 (from uvicorn==0.38.0)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth==2.29.0)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth==2.29.0)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth==2.29.0)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0+cu124)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow==2.12.1)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow==2.12.1)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow==2.12.1)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from Flask<4->mlflow==2.12.1)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow==2.12.1)\n",
      "  Using cached werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow==2.12.1)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.12.1)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==2.12.1)\n",
      "  Using cached graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==2.12.1)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.12.1)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3->mlflow==2.12.1)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth==2.29.0)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow==2.12.1)\n",
      "  Using cached greenlet-3.3.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.50.0,>=0.40.0->fastapi==0.121.2)\n",
      "  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: psutil in /root/.venv/lib/python3.12/site-packages (from peft) (7.1.3)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.6.0+cu124)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (1.8.19)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (9.8.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (8.7.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (6.5.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /root/.venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /root/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /root/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /root/.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /root/.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /root/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /root/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /root/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Using cached fastapi-0.121.2-py3-none-any.whl (109 kB)\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached mlflow-2.12.1-py3-none-any.whl (20.2 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
      "Using cached scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "Using cached matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached pyarrow-15.0.2-cp312-cp312-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "Using cached sqlparse-0.5.5-py3-none-any.whl (46 kB)\n",
      "Using cached starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "Using cached bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Using cached greenlet-3.3.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (609 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, zipp, xxhash, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, sqlparse, sniffio, smmap, setuptools, safetensors, regex, querystring-parser, pyyaml, python-dotenv, pyparsing, pyasn1, protobuf, propcache, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, markupsafe, markdown, kiwisolver, joblib, jiter, itsdangerous, idna, hf-xet, h11, greenlet, graphql-core, fsspec, frozenlist, fonttools, filelock, entrypoints, distro, dill, cycler, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, attrs, annotated-types, annotated-doc, aiohappyeyeballs, yarl, werkzeug, uvicorn, typing-inspection, sqlalchemy, scipy, rsa, requests, pydantic-core, pyasn1-modules, pyarrow, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, Mako, Jinja2, importlib-metadata, httpcore, gunicorn, graphql-relay, gitdb, contourpy, anyio, aiosignal, starlette, scikit-learn, pydantic, nvidia-cusolver-cu12, matplotlib, huggingface-hub, httpx, graphene, google-auth, gitpython, Flask, docker, alembic, aiohttp, torch, tokenizers, openai, mlflow, fastapi, transformers, torchvision, datasets, bitsandbytes, accelerate, peft\n",
      "\u001b[2K  Attempting uninstall: packaging0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [pillow]f]s]12]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/118\u001b[0m [pillow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118/118\u001b[0m [peft]0m [peft]erate]tsandbytes]ub]cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Jinja2-3.1.6 Mako-1.3.10 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 attrs-25.4.0 bitsandbytes-0.49.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-3.1.2 contourpy-1.3.3 cycler-0.12.1 datasets-4.0.0 dill-0.3.8 distro-1.9.0 docker-7.1.0 entrypoints-0.4 fastapi-0.121.2 filelock-3.20.1 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.29.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 gunicorn-21.2.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 importlib-metadata-7.2.1 itsdangerous-2.2.0 jiter-0.12.0 joblib-1.5.3 kiwisolver-1.4.9 markdown-3.10 markupsafe-3.0.3 matplotlib-3.10.8 mlflow-2.12.1 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.16 networkx-3.6.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-2.14.0 packaging-24.2 pandas-2.3.3 peft-0.18.0 pillow-11.3.0 propcache-0.4.1 protobuf-5.29.5 pyarrow-15.0.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.3 pydantic-core-2.41.4 pyparsing-3.2.5 python-dotenv-1.0.1 pytz-2024.2 pyyaml-6.0.3 querystring-parser-1.2.4 regex-2025.11.3 requests-2.32.5 rsa-4.9.1 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 setuptools-80.9.0 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.45 sqlparse-0.5.5 starlette-0.49.3 sympy-1.13.1 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.6.0+cu124 torchvision-0.21.0+cu124 tqdm-4.67.1 transformers-4.57.3 triton-3.2.0 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 uvicorn-0.38.0 werkzeug-3.1.4 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi==0.121.2 pydantic==2.12.3 mlflow==2.12.1 \\\n",
    "  torch==2.6.0+cu124 torchvision==0.21.0+cu124 \\\n",
    "  pillow==11.3.0 numpy==1.26.4 requests==2.32.5 uvicorn==0.38.0 \\\n",
    "  python-dotenv==1.0.1 google-auth==2.29.0 \\\n",
    "  transformers peft bitsandbytes datasets scikit-learn openai matplotlib ipykernel \\\n",
    "  --extra-index-url https://download.pytorch.org/whl/cu124\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8683a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    AutoModelForVision2Seq,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e7b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3VLForConditionalGeneration(\n",
       "      (model): Qwen3VLModel(\n",
       "        (visual): Qwen3VLVisionModel(\n",
       "          (patch_embed): Qwen3VLVisionPatchEmbed(\n",
       "            (proj): Conv3d(3, 1152, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "          )\n",
       "          (pos_embed): Embedding(2304, 1152)\n",
       "          (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
       "          (blocks): ModuleList(\n",
       "            (0-26): 27 x Qwen3VLVisionBlock(\n",
       "              (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (attn): Qwen3VLVisionAttention(\n",
       "                (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
       "                (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "              )\n",
       "              (mlp): Qwen3VLVisionMLP(\n",
       "                (linear_fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "                (linear_fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "                (act_fn): GELUTanh()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (merger): Qwen3VLVisionPatchMerger(\n",
       "            (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "            (linear_fc1): Linear4bit(in_features=4608, out_features=4608, bias=True)\n",
       "            (act_fn): GELU(approximate='none')\n",
       "            (linear_fc2): Linear4bit(in_features=4608, out_features=4096, bias=True)\n",
       "          )\n",
       "          (deepstack_merger_list): ModuleList(\n",
       "            (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
       "              (norm): LayerNorm((4608,), eps=1e-06, elementwise_affine=True)\n",
       "              (linear_fc1): Linear4bit(in_features=4608, out_features=4608, bias=True)\n",
       "              (act_fn): GELU(approximate='none')\n",
       "              (linear_fc2): Linear4bit(in_features=4608, out_features=4096, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (language_model): Qwen3VLTextModel(\n",
       "          (embed_tokens): Embedding(151936, 4096)\n",
       "          (layers): ModuleList(\n",
       "            (0-35): 36 x Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "          )\n",
       "          (norm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "          (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "adapter_path = \"./qlora-adapter\"   # QLoRA 결과\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    base_model,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# base model\n",
    "base = AutoModelForVision2Seq.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# LoRA adapter 결합\n",
    "model = PeftModel.from_pretrained(base, adapter_path)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff1461",
   "metadata": {},
   "source": [
    "### 테스트 입력 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95206f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../mixture_data/아토피/H5_924_P7_L5.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5b07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지 구성: chat template + image token 구조\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"너는 얼굴 이미지를 참고하여 식단 JSON만 생성하는 모델이다.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"진단: 아토피\\n\"\n",
    "                    \"키/몸무게/활동/목표: 162cm, 69kg, LOW, GAIN\\n\"\n",
    "                    \"1식 칼로리 목표: 380 kcal\\n\"\n",
    "                    \"식이 룰: 오메가-3 우선, 가공식품 제한\\n\"\n",
    "                    \"반드시 JSON만 출력하라.\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b798e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text + image를 동시에 processor에 전달 (핵심)\n",
    "text = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False,   # 문자열로 반환\n",
    ")\n",
    "\n",
    "# device 이동\n",
    "inputs = processor(\n",
    "    images=[image],\n",
    "    text=text,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8492771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "너는 얼굴 이미지를 참고하여 식단 JSON만 생성하는 모델이다.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>진단: 아토피\n",
      "키/몸무게/활동/목표: 162cm, 69kg, LOW, GAIN\n",
      "1식 칼로리 목표: 380 kcal\n",
      "식이 룰: 오메가-3 우선, 가공식품 제한\n",
      "반드시 JSON만 출력하라.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "[{\"calories\": 320, \"description\": \"오메가-3와 단백질 공급\", \"menuName\": \"연어구이\", \"notes\": \"소금 적게\"}, {\"calories\": 180, \"description\": \"항산화로 피부 개선 도움\", \"menuName\": \"브로콜리찜\", \"notes\": \"올리브오일 소량\"}, {\"calories\": 220, \"description\": \"복합탄수화물로 포만감 제공\", \"menuName\": \"오곡밥\", \"notes\": \"양 조절\"}]<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "generated_ids = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "decoded = processor.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
