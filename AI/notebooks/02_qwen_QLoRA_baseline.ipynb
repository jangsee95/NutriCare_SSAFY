{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8630943a",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q \"transformers>=4.42.0\" \"accelerate>=0.30.0\" bitsandbytes peft datasets torchvision pillow mlflow\n",
    "import torch, transformers, mlflow\n",
    "print(\"torch\", torch.__version__, \"cuda\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acfb73",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '{' (2419650234.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m*sample(=, {)\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m closing parenthesis ')' does not match opening parenthesis '{'\n"
     ]
    }
   ],
   "source": [
    "# # 데이터 예시\n",
    "# sample = {\n",
    "#   \"image\": \"/path/to/photo.jpg\",  # 얼굴 이미지 1장\n",
    "#   \"diagnosis_name\": \"acne\",       # ResNet/analysis_result 라벨\n",
    "#   \"health_profile\": \"height 172cm, weight 66kg, activity moderate, goal: cut 0.5kg/week\",\n",
    "#   \"diet_recommendation_meta\": \"rec_id=123, memo=초기 상담, created_at=2024-01-01\",\n",
    "#   \"rules\": \"허용: 저당, 오메가3 / 제한: 고당, 포화지방 / 조건: 1식 550kcal\",\n",
    "#   \"calorie_plan\": 550,\n",
    "#   \"diet_json\": [\n",
    "#     {\"menuName\": \"연어 샐러드\", \"description\": \"훈제연어+채소\", \"calories\": 520, \"notes\": \"오메가3\", \"recipeUrl\": \"...\"},\n",
    "#     {\"menuName\": \"두부 비빔밥\", \"description\": \"현미, 두부, 채소\", \"calories\": 560, \"notes\": \"저당\", \"recipeUrl\": \"...\"},\n",
    "#   ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f09fd7",
   "metadata": {},
   "source": [
    "### 1) 모델/프로세서(Qwen3-VL-7B , 4bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "base_model = \"Qwen/Qwen3-VL-7B-Instruct\"  # VRAM 맞춰 조정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_model, trust_remote_code=True)\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e944c6",
   "metadata": {},
   "source": [
    "## 2) LoRA 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99fad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684257ba",
   "metadata": {},
   "source": [
    "## 3) 데이터/콜레이터\n",
    "- 샘플 리스트로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "def build_prompt(record):\n",
    "    sys_prompt = (\n",
    "        \"You are a dietitian VLM. See the meal image and propose 3-4 diet options as JSON array. \"\n",
    "        \"Keys: menuName, description, calories, notes, recipeUrl(optional), skincareUrl(optional). \"\n",
    "        \"Calories integers (kcal).\"\n",
    "    )\n",
    "    user_prompt = (\n",
    "        f\"Image caption: {record['caption']}\\n\"\n",
    "        f\"Backup label: {record['resnet_label']}\\n\"\n",
    "        f\"Health info: {record['health_info']}\\n\"\n",
    "        f\"Rules: {record['rules']}\\n\"\n",
    "        f\"Calorie target per meal: {record['calorie_plan']} kcal\\n\"\n",
    "        \"Return JSON only.\"\n",
    "    )\n",
    "    return sys_prompt, user_prompt\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [Image.open(x[\"image\"]).convert(\"RGB\") for x in batch]\n",
    "    messages_list = []\n",
    "    for x, img in zip(batch, images):\n",
    "        sys_prompt, user_prompt = build_prompt(x)\n",
    "        messages_list.append([\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": img}, {\"type\": \"text\", \"text\": user_prompt}]},\n",
    "        ])\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    text_inputs = processor.apply_chat_template(messages_list, add_generation_prompt=False,\n",
    "                                                return_tensors=\"pt\", padding=True)\n",
    "    labels = text_inputs[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    return {\n",
    "        \"input_ids\": text_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": text_inputs[\"attention_mask\"],\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "# TODO: synthesize_sample() 등으로 채운 리스트 사용\n",
    "train_samples = []  # e.g., [{\"image\": \"...\", \"caption\": \"...\", ...}, ...]\n",
    "train_dataset = Dataset.from_list(train_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148cd787",
   "metadata": {},
   "source": [
    "## 4) MLflow 설정 + Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.integrations import MLflowCallback\n",
    "\n",
    "mlflow.set_experiment(\"qwen2vl-qlora\")\n",
    "# mlflow.set_tracking_uri(\"http://your-mlflow:5000\")  # 필요 시\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora-qwen2vl2b\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    logging_steps=5,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"mlflow\",           # 자동 로깅\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=[MLflowCallback()],  # 선택적이지만 추천\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84733960",
   "metadata": {},
   "source": [
    "## 5) 학습 + 로깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e14e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # 수동으로도 남기고 싶은 파라미터/메모 추가\n",
    "    mlflow.log_params({\n",
    "        \"lora_r\": lora_config.r,\n",
    "        \"lora_alpha\": lora_config.lora_alpha,\n",
    "        \"train_batch\": training_args.per_device_train_batch_size,\n",
    "        \"grad_accum\": training_args.gradient_accumulation_steps,\n",
    "        \"base_model\": base_model,\n",
    "    })\n",
    "    trainer.train()\n",
    "    # 어댑터/체크포인트 기록\n",
    "    save_dir = \"qlora-adapter\"\n",
    "    trainer.save_model(save_dir)\n",
    "    mlflow.log_artifacts(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde86b1",
   "metadata": {},
   "source": [
    "## 6) 추론용 어댑터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70752d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "base_infer = AutoModelForVision2Seq.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "peft_infer = PeftModel.from_pretrained(base_infer, \"qlora-adapter\")\n",
    "peft_infer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
